digraph {
	graph [size="59.55,59.55"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2828830588528 [label="
 (1, 24)" fillcolor=darkolivegreen1]
	2828830474048 [label=AddmmBackward0]
	2828830472608 -> 2828830474048
	2828830588688 [label="resnet.fc.bias
 (24)" fillcolor=lightblue]
	2828830588688 -> 2828830472608
	2828830472608 [label=AccumulateGrad]
	2828830473328 -> 2828830474048
	2828830473328 [label=ViewBackward0]
	2828830473424 -> 2828830473328
	2828830473424 [label=MeanBackward1]
	2828830471792 -> 2828830473424
	2828830471792 [label=ReluBackward0]
	2828830471216 -> 2828830471792
	2828830471216 [label=AddBackward0]
	2828830468672 -> 2828830471216
	2828830468672 [label=NativeBatchNormBackward0]
	2828830470016 -> 2828830468672
	2828830470016 [label=ConvolutionBackward0]
	2828830468096 -> 2828830470016
	2828830468096 [label=ReluBackward0]
	2828830467424 -> 2828830468096
	2828830467424 [label=NativeBatchNormBackward0]
	2828830466800 -> 2828830467424
	2828830466800 [label=ConvolutionBackward0]
	2828830470736 -> 2828830466800
	2828830470736 [label=ReluBackward0]
	2828830465072 -> 2828830470736
	2828830465072 [label=AddBackward0]
	2828830464544 -> 2828830465072
	2828830464544 [label=NativeBatchNormBackward0]
	2828830464064 -> 2828830464544
	2828830464064 [label=ConvolutionBackward0]
	2828830463488 -> 2828830464064
	2828830463488 [label=ReluBackward0]
	2828830463152 -> 2828830463488
	2828830463152 [label=NativeBatchNormBackward0]
	2828830462768 -> 2828830463152
	2828830462768 [label=ConvolutionBackward0]
	2828830462240 -> 2828830462768
	2828830462240 [label=ReluBackward0]
	2828830461376 -> 2828830462240
	2828830461376 [label=AddBackward0]
	2828830460560 -> 2828830461376
	2828830460560 [label=NativeBatchNormBackward0]
	2828830459456 -> 2828830460560
	2828830459456 [label=ConvolutionBackward0]
	2828830460272 -> 2828830459456
	2828830460272 [label=ReluBackward0]
	2828830617280 -> 2828830460272
	2828830617280 [label=NativeBatchNormBackward0]
	2828830617088 -> 2828830617280
	2828830617088 [label=ConvolutionBackward0]
	2828830461280 -> 2828830617088
	2828830461280 [label=ReluBackward0]
	2828830616608 -> 2828830461280
	2828830616608 [label=AddBackward0]
	2828830616416 -> 2828830616608
	2828830616416 [label=NativeBatchNormBackward0]
	2828830616176 -> 2828830616416
	2828830616176 [label=ConvolutionBackward0]
	2828830615792 -> 2828830616176
	2828830615792 [label=ReluBackward0]
	2828830615552 -> 2828830615792
	2828830615552 [label=NativeBatchNormBackward0]
	2828830615360 -> 2828830615552
	2828830615360 [label=ConvolutionBackward0]
	2828830614976 -> 2828830615360
	2828830614976 [label=ReluBackward0]
	2828830614832 -> 2828830614976
	2828830614832 [label=AddBackward0]
	2828830614640 -> 2828830614832
	2828830614640 [label=NativeBatchNormBackward0]
	2828830614304 -> 2828830614640
	2828830614304 [label=ConvolutionBackward0]
	2828830614016 -> 2828830614304
	2828830614016 [label=ReluBackward0]
	2828830613776 -> 2828830614016
	2828830613776 [label=NativeBatchNormBackward0]
	2828830613584 -> 2828830613776
	2828830613584 [label=ConvolutionBackward0]
	2828830614688 -> 2828830613584
	2828830614688 [label=ReluBackward0]
	2828830613104 -> 2828830614688
	2828830613104 [label=AddBackward0]
	2828830612912 -> 2828830613104
	2828830612912 [label=NativeBatchNormBackward0]
	2828830612576 -> 2828830612912
	2828830612576 [label=ConvolutionBackward0]
	2828830612288 -> 2828830612576
	2828830612288 [label=ReluBackward0]
	2828830612048 -> 2828830612288
	2828830612048 [label=NativeBatchNormBackward0]
	2828830611856 -> 2828830612048
	2828830611856 [label=ConvolutionBackward0]
	2828830611472 -> 2828830611856
	2828830611472 [label=ReluBackward0]
	2828830611232 -> 2828830611472
	2828830611232 [label=AddBackward0]
	2828830611040 -> 2828830611232
	2828830611040 [label=NativeBatchNormBackward0]
	2828830610800 -> 2828830611040
	2828830610800 [label=ConvolutionBackward0]
	2828830610512 -> 2828830610800
	2828830610512 [label=ReluBackward0]
	2828830610176 -> 2828830610512
	2828830610176 [label=NativeBatchNormBackward0]
	2828830609984 -> 2828830610176
	2828830609984 [label=ConvolutionBackward0]
	2828830611184 -> 2828830609984
	2828830611184 [label=ReluBackward0]
	2828830609504 -> 2828830611184
	2828830609504 [label=AddBackward0]
	2828830609312 -> 2828830609504
	2828830609312 [label=NativeBatchNormBackward0]
	2828830609072 -> 2828830609312
	2828830609072 [label=ConvolutionBackward0]
	2828830608784 -> 2828830609072
	2828830608784 [label=ReluBackward0]
	2828830608448 -> 2828830608784
	2828830608448 [label=NativeBatchNormBackward0]
	2828830608256 -> 2828830608448
	2828830608256 [label=ConvolutionBackward0]
	2828830609456 -> 2828830608256
	2828830609456 [label=MaxPool2DWithIndicesBackward0]
	2828830607776 -> 2828830609456
	2828830607776 [label=ReluBackward0]
	2828830607584 -> 2828830607776
	2828830607584 [label=NativeBatchNormBackward0]
	2828830607392 -> 2828830607584
	2828830607392 [label=ConvolutionBackward0]
	2828830607104 -> 2828830607392
	2828727036048 [label="resnet.conv1.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	2828727036048 -> 2828830607104
	2828830607104 [label=AccumulateGrad]
	2828830607536 -> 2828830607584
	2828791539696 [label="resnet.bn1.weight
 (64)" fillcolor=lightblue]
	2828791539696 -> 2828830607536
	2828830607536 [label=AccumulateGrad]
	2828830608064 -> 2828830607584
	2828727036128 [label="resnet.bn1.bias
 (64)" fillcolor=lightblue]
	2828727036128 -> 2828830608064
	2828830608064 [label=AccumulateGrad]
	2828830607968 -> 2828830608256
	2828727041488 [label="resnet.layer1.0.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2828727041488 -> 2828830607968
	2828830607968 [label=AccumulateGrad]
	2828830608400 -> 2828830608448
	2828727030048 [label="resnet.layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	2828727030048 -> 2828830608400
	2828830608400 [label=AccumulateGrad]
	2828830608640 -> 2828830608448
	2828727041408 [label="resnet.layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	2828727041408 -> 2828830608640
	2828830608640 [label=AccumulateGrad]
	2828830608832 -> 2828830609072
	2828830282576 [label="resnet.layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2828830282576 -> 2828830608832
	2828830608832 [label=AccumulateGrad]
	2828830609120 -> 2828830609312
	2828830282496 [label="resnet.layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	2828830282496 -> 2828830609120
	2828830609120 [label=AccumulateGrad]
	2828830609264 -> 2828830609312
	2828830282656 [label="resnet.layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	2828830282656 -> 2828830609264
	2828830609264 [label=AccumulateGrad]
	2828830609456 -> 2828830609504
	2828830609696 -> 2828830609984
	2828830283136 [label="resnet.layer1.1.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2828830283136 -> 2828830609696
	2828830609696 [label=AccumulateGrad]
	2828830610128 -> 2828830610176
	2828830283056 [label="resnet.layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	2828830283056 -> 2828830610128
	2828830610128 [label=AccumulateGrad]
	2828830610368 -> 2828830610176
	2828830283216 [label="resnet.layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	2828830283216 -> 2828830610368
	2828830610368 [label=AccumulateGrad]
	2828830610560 -> 2828830610800
	2828830283776 [label="resnet.layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2828830283776 -> 2828830610560
	2828830610560 [label=AccumulateGrad]
	2828830610848 -> 2828830611040
	2828830283696 [label="resnet.layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	2828830283696 -> 2828830610848
	2828830610848 [label=AccumulateGrad]
	2828830610992 -> 2828830611040
	2828830283856 [label="resnet.layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	2828830283856 -> 2828830610992
	2828830610992 [label=AccumulateGrad]
	2828830611184 -> 2828830611232
	2828830611520 -> 2828830611856
	2828830284976 [label="resnet.layer2.0.conv1.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	2828830284976 -> 2828830611520
	2828830611520 [label=AccumulateGrad]
	2828830611904 -> 2828830612048
	2828830284896 [label="resnet.layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	2828830284896 -> 2828830611904
	2828830611904 [label=AccumulateGrad]
	2828830612240 -> 2828830612048
	2828830285056 [label="resnet.layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	2828830285056 -> 2828830612240
	2828830612240 [label=AccumulateGrad]
	2828830612336 -> 2828830612576
	2828830285616 [label="resnet.layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2828830285616 -> 2828830612336
	2828830612336 [label=AccumulateGrad]
	2828830612720 -> 2828830612912
	2828830285536 [label="resnet.layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	2828830285536 -> 2828830612720
	2828830612720 [label=AccumulateGrad]
	2828830612768 -> 2828830612912
	2828830285696 [label="resnet.layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	2828830285696 -> 2828830612768
	2828830612768 [label=AccumulateGrad]
	2828830612960 -> 2828830613104
	2828830612960 [label=NativeBatchNormBackward0]
	2828830611664 -> 2828830612960
	2828830611664 [label=ConvolutionBackward0]
	2828830611472 -> 2828830611664
	2828830611424 -> 2828830611664
	2828830284256 [label="resnet.layer2.0.downsample.0.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	2828830284256 -> 2828830611424
	2828830611424 [label=AccumulateGrad]
	2828830612384 -> 2828830612960
	2828830284336 [label="resnet.layer2.0.downsample.1.weight
 (128)" fillcolor=lightblue]
	2828830284336 -> 2828830612384
	2828830612384 [label=AccumulateGrad]
	2828830612528 -> 2828830612960
	2828830284416 [label="resnet.layer2.0.downsample.1.bias
 (128)" fillcolor=lightblue]
	2828830284416 -> 2828830612528
	2828830612528 [label=AccumulateGrad]
	2828830613200 -> 2828830613584
	2828830286176 [label="resnet.layer2.1.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2828830286176 -> 2828830613200
	2828830613200 [label=AccumulateGrad]
	2828830613632 -> 2828830613776
	2828830286096 [label="resnet.layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	2828830286096 -> 2828830613632
	2828830613632 [label=AccumulateGrad]
	2828830613968 -> 2828830613776
	2828830286256 [label="resnet.layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	2828830286256 -> 2828830613968
	2828830613968 [label=AccumulateGrad]
	2828830614064 -> 2828830614304
	2828830286736 [label="resnet.layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2828830286736 -> 2828830614064
	2828830614064 [label=AccumulateGrad]
	2828830614448 -> 2828830614640
	2828830286656 [label="resnet.layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	2828830286656 -> 2828830614448
	2828830614448 [label=AccumulateGrad]
	2828830614496 -> 2828830614640
	2828830286816 [label="resnet.layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	2828830286816 -> 2828830614496
	2828830614496 [label=AccumulateGrad]
	2828830614688 -> 2828830614832
	2828830615120 -> 2828830615360
	2828830288096 [label="resnet.layer3.0.conv1.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	2828830288096 -> 2828830615120
	2828830615120 [label=AccumulateGrad]
	2828830615504 -> 2828830615552
	2828830288016 [label="resnet.layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	2828830288016 -> 2828830615504
	2828830615504 [label=AccumulateGrad]
	2828830615744 -> 2828830615552
	2828830288176 [label="resnet.layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	2828830288176 -> 2828830615744
	2828830615744 [label=AccumulateGrad]
	2828830615840 -> 2828830616176
	2828830288736 [label="resnet.layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2828830288736 -> 2828830615840
	2828830615840 [label=AccumulateGrad]
	2828830616224 -> 2828830616416
	2828830288656 [label="resnet.layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	2828830288656 -> 2828830616224
	2828830616224 [label=AccumulateGrad]
	2828830616368 -> 2828830616416
	2828830288816 [label="resnet.layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	2828830288816 -> 2828830616368
	2828830616368 [label=AccumulateGrad]
	2828830616560 -> 2828830616608
	2828830616560 [label=NativeBatchNormBackward0]
	2828830615168 -> 2828830616560
	2828830615168 [label=ConvolutionBackward0]
	2828830614976 -> 2828830615168
	2828830614928 -> 2828830615168
	2828830287296 [label="resnet.layer3.0.downsample.0.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	2828830287296 -> 2828830614928
	2828830614928 [label=AccumulateGrad]
	2828830615984 -> 2828830616560
	2828830287376 [label="resnet.layer3.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	2828830287376 -> 2828830615984
	2828830615984 [label=AccumulateGrad]
	2828830616032 -> 2828830616560
	2828830287456 [label="resnet.layer3.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	2828830287456 -> 2828830616032
	2828830616032 [label=AccumulateGrad]
	2828830616704 -> 2828830617088
	2828830289296 [label="resnet.layer3.1.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2828830289296 -> 2828830616704
	2828830616704 [label=AccumulateGrad]
	2828830617232 -> 2828830617280
	2828830289216 [label="resnet.layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	2828830289216 -> 2828830617232
	2828830617232 [label=AccumulateGrad]
	2828830617472 -> 2828830617280
	2828830289376 [label="resnet.layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	2828830289376 -> 2828830617472
	2828830617472 [label=AccumulateGrad]
	2828830617424 -> 2828830459456
	2828830289936 [label="resnet.layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2828830289936 -> 2828830617424
	2828830617424 [label=AccumulateGrad]
	2828830459552 -> 2828830460560
	2828830289856 [label="resnet.layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	2828830289856 -> 2828830459552
	2828830459552 [label=AccumulateGrad]
	2828830460464 -> 2828830460560
	2828830290016 [label="resnet.layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	2828830290016 -> 2828830460464
	2828830460464 [label=AccumulateGrad]
	2828830461280 -> 2828830461376
	2828830462336 -> 2828830462768
	2828830291296 [label="resnet.layer4.0.conv1.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	2828830291296 -> 2828830462336
	2828830462336 [label=AccumulateGrad]
	2828830462912 -> 2828830463152
	2828830291216 [label="resnet.layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	2828830291216 -> 2828830462912
	2828830462912 [label=AccumulateGrad]
	2828830463440 -> 2828830463152
	2828830291376 [label="resnet.layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	2828830291376 -> 2828830463440
	2828830463440 [label=AccumulateGrad]
	2828830463536 -> 2828830464064
	2828830291936 [label="resnet.layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2828830291936 -> 2828830463536
	2828830463536 [label=AccumulateGrad]
	2828830464304 -> 2828830464544
	2828830291856 [label="resnet.layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	2828830291856 -> 2828830464304
	2828830464304 [label=AccumulateGrad]
	2828830464400 -> 2828830464544
	2828830292016 [label="resnet.layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	2828830292016 -> 2828830464400
	2828830464400 [label=AccumulateGrad]
	2828830464688 -> 2828830465072
	2828830464688 [label=NativeBatchNormBackward0]
	2828830462480 -> 2828830464688
	2828830462480 [label=ConvolutionBackward0]
	2828830462240 -> 2828830462480
	2828830461904 -> 2828830462480
	2828830290496 [label="resnet.layer4.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	2828830290496 -> 2828830461904
	2828830461904 [label=AccumulateGrad]
	2828830463680 -> 2828830464688
	2828830290576 [label="resnet.layer4.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	2828830290576 -> 2828830463680
	2828830463680 [label=AccumulateGrad]
	2828830463920 -> 2828830464688
	2828830290656 [label="resnet.layer4.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	2828830290656 -> 2828830463920
	2828830463920 [label=AccumulateGrad]
	2828830465504 -> 2828830466800
	2828830292496 [label="resnet.layer4.1.conv1.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2828830292496 -> 2828830465504
	2828830465504 [label=AccumulateGrad]
	2828830466896 -> 2828830467424
	2828830292416 [label="resnet.layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	2828830292416 -> 2828830466896
	2828830466896 [label=AccumulateGrad]
	2828830468000 -> 2828830467424
	2828830292576 [label="resnet.layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	2828830292576 -> 2828830468000
	2828830468000 [label=AccumulateGrad]
	2828830468576 -> 2828830470016
	2828830293056 [label="resnet.layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2828830293056 -> 2828830468576
	2828830468576 [label=AccumulateGrad]
	2828830469392 -> 2828830468672
	2828830292976 [label="resnet.layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	2828830292976 -> 2828830469392
	2828830469392 [label=AccumulateGrad]
	2828830469296 -> 2828830468672
	2828830293136 [label="resnet.layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	2828830293136 -> 2828830469296
	2828830469296 [label=AccumulateGrad]
	2828830470736 -> 2828830471216
	2828830473232 -> 2828830474048
	2828830473232 [label=TBackward0]
	2828830471312 -> 2828830473232
	2828830588848 [label="resnet.fc.weight
 (24, 512)" fillcolor=lightblue]
	2828830588848 -> 2828830471312
	2828830471312 [label=AccumulateGrad]
	2828830474048 -> 2828830588528
}
